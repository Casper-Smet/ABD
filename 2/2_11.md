# Excercise 2.11

2.11 Consider a modified version of the vacuum environment in Exercise 2.8, in which the geography of the environment—its extent, boundaries, and obstacles—is unknown, as is the initial dirt configuration. (The agent can go Up and Down as well as Left and Right.)

- a. Can a simple reflex agent be perfectly rational for this environment? Explain.
  - De agent maakt geen model van de environment en zal hierdoor hoogstwaarschijnlijk schone tiles meerdere malen bezoeken.
- b. Can a simple reflex agent with a randomized agent function outperform a simple reflex agent? Design such an agent and measure its performance on several environments.
  - Het willekeurig bewegen bevorderd de exploratie en zorgt ervoor dat de agent niet vast komt te zitten tegen bijvoorbeeld een muur of doodlopende gang.
- c. Can you design an environment in which your randomized agent will perform poorly? Show your results.
  - Een environment met zeer smalle gangen. Bijvoorbeeld een van 8 tiles breed bij 2 tiles hoog. Hierdoor zal de randomized agent regelmatig tegen de muren aan de boven- en onderkant lopen. Dit terwijl de reflex-agent continue horizontaal zou kunnen bewegen, mocht deze zo zijn geïmplementeerd.
- d. Can a reflex agent with state outperform a simple reflex agent? Design such an agent and measure its performance on several environments. Can you design a rational agent of this type?
  - Een agent met state kan alle bezochte tiles onthouden en zal, optimaal gezien, alleen de aangrenzende vlakken exploreren. Vervolgens kan de agent ontdekken of hier muren of nieuwe tiles zitten. Zodra alles bekend, en optimaal gezien, direct schoongemaakt is, heeft de agent een complete kaart van de environment. Echter is de environment nu al 'uitgespeeld'. Een volgende ronde op dezelfde environment kan dan wel gebruik maken van de al bekende kaart.
